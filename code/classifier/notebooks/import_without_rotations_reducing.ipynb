{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"import_without_rotations_reducing.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"sdyfwb_aZWNB","colab_type":"text"},"source":["# Configure enviroment"]},{"cell_type":"code","metadata":{"id":"q88TRW8TZIqs","colab_type":"code","outputId":"a47d3ae9-d6ba-4843-a021-9f8c4995072b","executionInfo":{"status":"ok","timestamp":1560818320591,"user_tz":180,"elapsed":24361,"user":{"displayName":"Douglas Henrique Maximo da Silva","photoUrl":"","userId":"10000444056635760542"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8jpumH0kZcy_","colab_type":"text"},"source":["# Imports"]},{"cell_type":"code","metadata":{"id":"8b4a2UbMY_2u","colab_type":"code","colab":{}},"source":["import math\n","import itertools\n","import re\n","import os\n","import imageio\n","import shutil\n","import numpy as np\n","import pandas as pd\n","from scipy.ndimage import rotate\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import KFold\n","from tqdm import tqdm\n","import random"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fIGx04rqrZEh","colab_type":"text"},"source":["# Settings"]},{"cell_type":"code","metadata":{"id":"ZfNtVy7rrYMI","colab_type":"code","colab":{}},"source":["# Begin Settings -------------------------|\n","\n","# Important folders\n","content_folder = \"/content/drive/My Drive/Pesquisa - Dicom images/data\"\n","ben_dir = content_folder + \"/images/solid-nodules-with-attributes/benigno\"\n","mal_dir = content_folder + \"/images/solid-nodules-with-attributes/maligno\"\n","features_path = content_folder + \"/features/solidNodules.csv\"\n","\n","# Random seed to get a better reproductibility\n","np.random.seed(1937)\n","\n","# If set True, it shows data informations in the output of the program\n","LOG = True\n","\n","# Images resolution\n","RES = 64\n","\n","# Size of the test fold\n","TEST_SIZE = 50\n","\n","# Number of slices for each nodule\n","SLICES = 5\n","\n","# Strategy used for normalization - it can be 'first' or 'balanced'\n","STRATEGY = 'first'\n","\n","'''If set True, it will repeat slices when the number of slices of a nodule is less than SLICES. \n","    If set False, the normalization will be filling with black images in the end'''\n","REPEAT = False\n","\n","# It makes the name for the folder where the numpies will be stored\n","\n","data_folder = content_folder + \"/no_aug_nps_reducing/data-\" + str(SLICES) + \"-\" + str(STRATEGY)\n","if (REPEAT):\n","    data_folder += \"-repeat\"\n","\n","# End settings ---------------------------|"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9IjafQlhrxCv","colab_type":"text"},"source":["# Get first slices Strategy\n","    Normalizes the nodule slices number:\n","    - A nodule with less than n slices is completed with black slices\n","    - A nodule with more than n slices have its n first slices selected"]},{"cell_type":"code","metadata":{"id":"-5V5vO3Jr29N","colab_type":"code","colab":{}},"source":["def normalize_first(nodules, n_slices, repeat=False):\n","    '''Normalizes the nodule slices number:\n","    - A nodule with less than n slices is completed with black slices\n","    - A nodule with more than n slices have its n first slices selected'''\n","\n","    normalized_slices = []\n","\n","    for nodule in nodules:\n","        new_nodule = []\n","\n","        if repeat:\n","            times = math.ceil(n_slices/len(nodule))\n","            nodule = list(itertools.chain.from_iterable(itertools.repeat(x, times) for x in nodule))\n","\n","        if len(nodule) <= n_slices:\n","                for slice in nodule:\n","                    new_nodule.append(slice)\n","                for i in range(n_slices - len(nodule)):\n","                    new_nodule.append(np.zeros((RES, RES)))\n","        elif len(nodule) > n_slices:\n","            for i in range(0, n_slices):\n","                new_nodule.append(nodule[i])\n","        normalized_slices.append(new_nodule)\n","    return normalized_slices"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5i4fM2JXr7w3","colab_type":"text"},"source":["# Read images and features, connecting each nodule to its features\n","Reads the image files and a .csv with the features of each nodule\n","    - path (string): path to the nodules folders\n","    - path_features (string): path to the features .csv\n","    - list: list of nodules with slices as Numpy Arrays\n","    - features: list of features corresponding to the nodules on list"]},{"cell_type":"code","metadata":{"id":"cXm9uJI2r9V0","colab_type":"code","colab":{}},"source":["def read_images(path, path_features):\n","    '''Reads the image files and a .csv with the features of each nodule\n","    Parameters:\n","        path (string): path to the nodules folders\n","        path_features (string): path to the features .csv\n","    Returns:\n","        list: list of nodules with slices as Numpy Arrays\n","        features: list of features corresponding to the nodules on list'''\n","\n","    df = pd.read_csv(path_features)\n","    allFeatures = df.values\n","\n","    list        = []\n","    features    = []\n","\n","    for _,dirs,_ in os.walk(path):\n","        for dirname in sorted(dirs, key=str.lower):\n","            for _,subdirs,_ in os.walk(path + \"/\" + dirname):\n","                for subdirname in sorted(subdirs, key=str.lower):\n","                    for root2,_,files2 in os.walk(path + \"/\" + dirname + \"/\" + subdirname):\n","                        slices      = []\n","                        files2[:]   = [re.findall('\\\\d+', x)[0] for x in files2]\n","\n","                        axis            = 0 # To get the Rows indices\n","                        examColumn      = 0 # Column of the csv where the exam code is\n","                        noduleColumn    = 1 # Column of the csv where the nodule code is\n","\n","                        # index of the rows that have the exam id equal to the exam id of the current nodule\n","                        indExam = np.where(allFeatures[:,examColumn] == dirname)[axis]\n","\n","                        # index of the rows that have the nodule id equal to the id of the current nodule\n","                        indNodule = np.where(allFeatures[:,noduleColumn] == subdirname)[axis]\n","\n","                        # Intersect the two arrays, which results in the row for the features \n","                        # of the current nodule\n","                        i = np.intersect1d(indExam,indNodule)\n","\n","                        # A list is returned, but there's just one value, so I used its index\n","                        index   = 0\n","                        exam    = allFeatures[i, examColumn][index]\n","                        nodule  = allFeatures[i, noduleColumn][index]\n","\n","                        '''Verify if there's more than one index for each nodule\n","                        and if there's divergence between the nodule image file location and the\n","                        csv values'''\n","\n","                        if((len(i) > 1) or (str(exam) != str(dirname)) or (str(nodule) != str(subdirname))):\n","                            print(\"Features error!\")\n","                        else:\n","                            '''Transform the list of index with just one value in a\n","                            primitive value to use as index to save the features values'''\n","                            i = i[0]\n","\n","                        for f in sorted(files2, key=float):\n","                            img = imageio.imread(root2 + \"/\" + f + \".png\", as_gray=True)\n","                            slices.append(img)\n","\n","                        list.append(slices)\n","                        features.append(allFeatures[i,2:74].tolist())\n","\n","    return list, features"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BmrOsaAOtu3W","colab_type":"text"},"source":["# Script to read and save data on numpy files"]},{"cell_type":"code","metadata":{"id":"zhnOboUGtvtO","colab_type":"code","outputId":"f0e857f1-1174-4b51-a746-c7648187d9ff","executionInfo":{"status":"ok","timestamp":1560822595648,"user_tz":180,"elapsed":3783406,"user":{"displayName":"Douglas Henrique Maximo da Silva","photoUrl":"","userId":"10000444056635760542"}},"colab":{"base_uri":"https://localhost:8080/","height":697}},"source":["if __name__ == \"__main__\":\n","\n","    print(\"Begin > \")\n","\n","    ben, f_ben = read_images(path=ben_dir, path_features=features_path)\n","    mal, f_mal = read_images(path=mal_dir, path_features=features_path)\n","\n","    if (STRATEGY == 'first'):\n","        ben = normalize_first(nodules=ben, n_slices=SLICES, repeat=REPEAT)\n","        mal = normalize_first(nodules=mal, n_slices=SLICES, repeat=REPEAT)\n","    else:\n","        ben = normalize_balanced(nodules=ben, n_slices=SLICES, repeat=REPEAT)\n","        mal = normalize_balanced(nodules=mal, n_slices=SLICES, repeat=REPEAT)\n","\n","    if LOG:\n","        print(\"Changind shape > \")\n","        print(\"     Ben as a list: \", len(ben))\n","        print(\"     Mal as a list: \", len(mal))\n","\n","    ben = np.concatenate(ben).reshape(len(ben), SLICES, RES, RES, 1)\n","    mal = np.concatenate(mal).reshape(len(mal), SLICES, RES, RES, 1)\n","    \n","    if LOG:\n","        print(\"     Ben as a numpy: \", ben.shape)\n","        print(\"     Mal as a numpy: \", mal.shape)\n","        print()\n","        print(\"Swaping axes > \")\n","\n","    ben = np.moveaxis(ben, 1, 3)\n","    mal = np.moveaxis(mal, 1, 3)\n","\n","    if LOG:\n","        print(\"     Ben new shape: \", ben.shape)\n","        print(\"     Mal new shape: \", mal.shape)\n","        print()\n","        print(\"Separating Train and Test > \")\n","\n","    ben_test_indices = np.random.choice(len(ben), TEST_SIZE, replace=False)\n","    mal_test_indices = np.random.choice(len(mal), TEST_SIZE, replace=False)\n","\n","    ben_test = np.array([ben[i] for i in ben_test_indices])\n","    f_ben_test = np.array([f_ben[i] for i in ben_test_indices])\n","\n","    mal_test = np.array([mal[i] for i in mal_test_indices])\n","    f_mal_test = np.array([f_mal[i] for i in mal_test_indices])\n","\n","    mal_train = np.delete(mal, mal_test_indices, axis=0)\n","    f_mal_train = np.delete(f_mal, mal_test_indices, axis=0)\n","\n","    ben_train_full      = np.delete(ben, ben_test_indices, axis=0)\n","    ben_train_ind       = np.random.choice(len(ben_train_full), len(mal_train), replace=False)\n","    ben_train           = np.array([ben_train_full[i] for i in ben_train_ind])\n","\n","    f_ben_train_full    = np.delete(f_ben, ben_test_indices, axis=0)\n","    f_ben_train         = np.array([f_ben_train_full[i] for i in ben_train_ind])\n","\n","    # Clean memory\n","    del(ben, f_ben, mal, f_mal, ben_dir, mal_dir, features_path, ben_test_indices, mal_test_indices)\n","\n","    if LOG:\n","        print(\"     Ben train: \", ben_train.shape)\n","        print(\"     Ben test: \", ben_test.shape)\n","        print()\n","        print(\"     Ben features train: \", f_ben_train.shape)\n","        print(\"     Ben features test: \", f_ben_test.shape)\n","        print()\n","        print(\"     Mal train: \", mal_train.shape)\n","        print(\"     Mal test: \", mal_test.shape)\n","        print()\n","        print(\"     Mal features train: \", f_mal_train.shape)\n","        print(\"     Mal features test: \", f_mal_test.shape)\n","        print()\n","        print(\"Data reduction > \")\n","\n","    if LOG:\n","        print(\"     Ben train: \", ben_train.shape)\n","        print(\"     Ben features train: \", f_ben_train.shape)\n","        print()\n","        print(\"     Mal train: \", mal_train.shape)\n","        print(\"     Mal features train: \", f_mal_train.shape)\n","        print()\n","        print(\"Concatenating Ben and Mal > \")\n","\n","    X_train = np.concatenate([ben_train, mal_train])\n","    f_train = np.concatenate([f_ben_train, f_mal_train])\n","\n","    X_test  = np.concatenate([ben_test, mal_test])\n","    f_test  = np.concatenate([f_ben_test, f_mal_test])\n","\n","    if LOG:\n","        print(\"     X_train: \", X_train.shape)\n","        print(\"     f_train: \", f_train.shape)\n","        print()\n","        print(\"     X_test: \", X_test.shape)\n","        print(\"     f_test: \", f_test.shape)\n","\n","        print()\n","        print(\"Generating labels and saving numpies on disk > \")\n","    \n","    train_labels = len(ben_train) * [0] + len(mal_train) * [1]\n","    Y_train = np.array(train_labels)\n","\n","    test_labels = len(ben_test) * [0] + len(mal_test) * [1]\n","    Y_test = np.array(test_labels)\n","    \n","    shutil.rmtree(data_folder, ignore_errors=True)\n","    os.mkdir(data_folder)\n","\n","    np.save(data_folder + \"/f_train.npy\", f_train)\n","    np.save(data_folder + \"/f_test.npy\", f_test)\n","    np.save(data_folder + \"/X_train.npy\", X_train)\n","    np.save(data_folder + \"/X_test.npy\", X_test)\n","    np.save(data_folder + \"/Y_train.npy\", Y_train)\n","    np.save(data_folder + \"/Y_test.npy\", Y_test)\n","    \n","    print(\"Finished!\")"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Begin > \n","Changind shape > \n","     Ben as a list:  615\n","     Mal as a list:  267\n","     Ben as a numpy:  (615, 5, 64, 64, 1)\n","     Mal as a numpy:  (267, 5, 64, 64, 1)\n","\n","Swaping axes > \n","     Ben new shape:  (615, 64, 64, 5, 1)\n","     Mal new shape:  (267, 64, 64, 5, 1)\n","\n","Separating Train and Test > \n","     Ben train:  (217, 64, 64, 5, 1)\n","     Ben test:  (50, 64, 64, 5, 1)\n","\n","     Ben features train:  (217, 72)\n","     Ben features test:  (50, 72)\n","\n","     Mal train:  (217, 64, 64, 5, 1)\n","     Mal test:  (50, 64, 64, 5, 1)\n","\n","     Mal features train:  (217, 72)\n","     Mal features test:  (50, 72)\n","\n","Data reduction > \n","     Ben train:  (217, 64, 64, 5, 1)\n","     Ben features train:  (217, 72)\n","\n","     Mal train:  (217, 64, 64, 5, 1)\n","     Mal features train:  (217, 72)\n","\n","Concatenating Ben and Mal > \n","     X_train:  (434, 64, 64, 5, 1)\n","     f_train:  (434, 72)\n","\n","     X_test:  (100, 64, 64, 5, 1)\n","     f_test:  (100, 72)\n","\n","Generating labels and saving numpies on disk > \n","Finished!\n"],"name":"stdout"}]}]}