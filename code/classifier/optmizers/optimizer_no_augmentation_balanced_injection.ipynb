{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "optimizer_no_augmentation_balanced_injection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YniqkXDJ5YW7",
        "colab_type": "text"
      },
      "source": [
        "# Env Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlQCyABiAiKc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "62fd5047-2d96-4ff0-962c-7ed27d322a0c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive', force_remount=True)\n",
        "!pip install keras_metrics"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at drive\n",
            "Requirement already satisfied: keras_metrics in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.6/dist-packages (from keras_metrics) (2.2.5)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (2.8.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras_metrics) (1.3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpsuDVzrYKVD",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN_yFwwqYKVF",
        "colab_type": "code",
        "outputId": "ad934bae-ea3f-4a97-c634-36f90dce312e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import os\n",
        "import time\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import interp, stats\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from keras.layers import Conv3D, MaxPool3D, Flatten, Dense, Dropout, Input, concatenate\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils.vis_utils import plot_model, model_to_dot\n",
        "import keras_metrics as km\n",
        "import math\n",
        "import itertools\n",
        "import re\n",
        "import os\n",
        "import imageio\n",
        "from scipy.ndimage import rotate\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "'''fixed settings'''\n",
        "rotations_of_benignant    = 5\n",
        "rotations_of_malignant    = 13\n",
        "slices_per_nodule         = 5\n",
        "number_of_folds           = 10\n",
        "strategy                  = 'first'\n",
        "repeat_slices             = False\n",
        "base_dir                  = \"/content/drive/My Drive/Master's degree/Research/data/\"\n",
        "images_dir                = base_dir + \"images/solid-nodules-with-attributes/\"\n",
        "features_path             = base_dir + \"features/solidNodules.csv\"\n",
        "images_resolution         = 64\n",
        "metrics                   = {'acc': [], 'spec': [], 'sens': [], 'f1_score': [], 'auc': []}\n",
        "number_of_validations     = 1\n",
        "drop_random_values_gen    = stats.norm(scale=0.05, loc=0.4)\n",
        "conv1_search_space        = [32, 48, 64, 96]\n",
        "dense1_search_space       = [32, 64, 128]\n",
        "dense2_search_space       = [16, 24, 32]\n",
        "\n",
        "'''Flexible settings'''\n",
        "input_shape = (64, 64, 5, 1)\n",
        "\n",
        "feature_injection    = True\n",
        "layer_to_be_injected = 'flatten' #flatten, dense1, dense2\n",
        "features_set         = 'all'     #all, opt, margin, shape \n",
        "experiment_name      = layer_to_be_injected + ' - ' + features_set if (feature_injection)  else 'none'\n",
        "\n",
        "def feat_input_shape():\n",
        "  if (features_set == 'all'):\n",
        "    return (71,)\n",
        "  elif (features_set == 'opt'):\n",
        "    return (38,)\n",
        "  elif (features_set == 'margin'):\n",
        "    return (12,)\n",
        "  elif (features_set == 'shape'):\n",
        "    return (8,)\n",
        "  \n",
        "def feat_input_subset():\n",
        "  if (features_set == 'opt'):\n",
        "    return optimized_features_set\n",
        "  elif (features_set == 'margin'):\n",
        "    return margin_features_set\n",
        "  elif (features_set == 'shape'):\n",
        "    return shape_features_set\n",
        "\n",
        "feature_input_shape    = feat_input_shape()\n",
        "shape_features_set     = [16, 17, 18, 19, 20, 21, 22, 23]\n",
        "margin_features_set    = [61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72]\n",
        "optimized_features_set = [2, 3, 4, 6, 9, 11, 12, 18, 19, 22, 26, 28, 29, \n",
        "                             30, 31, 32, 33, 35, 38, 40, 41, 44, 46, 47, 48, \n",
        "                             50, 53, 54, 56, 57, 59, 60, 62, 63, 65, 67, 71, 72]\n",
        "  \n",
        "print(\"Feature injection: \"    + str(feature_injection))\n",
        "print(\"Layer to be injected: \" + layer_to_be_injected)\n",
        "print(\"Features set: \"         + features_set)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature injection: True\n",
            "Layer to be injected: flatten\n",
            "Features set: all\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ74XWbH5QZj",
        "colab_type": "text"
      },
      "source": [
        "## Normalize getting the first slices (Unchanging)\n",
        "Function that normalize getting the first slices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBBPHYNH2YU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_first(nodules, n_slices, repeat=False):\n",
        "    '''Normalizes the nodule slices number:\n",
        "    - A nodule with less than n slices is completed with black slices\n",
        "    - A nodule with more than n slices have its n first slices selected'''\n",
        "    \n",
        "    normalized_slices = []\n",
        "\n",
        "    for nodule in nodules:\n",
        "        new_nodule = []\n",
        "\n",
        "        if repeat:\n",
        "            times = math.ceil(n_slices/len(nodule))\n",
        "            nodule = list(itertools.chain.from_iterable(itertools.repeat(x, times) for x in nodule))\n",
        "\n",
        "        if len(nodule) <= n_slices:\n",
        "                for slice in nodule:\n",
        "                    new_nodule.append(slice)\n",
        "                for i in range(n_slices - len(nodule)):\n",
        "                    new_nodule.append(np.zeros((images_resolution, images_resolution)))\n",
        "        elif len(nodule) > n_slices:\n",
        "            for i in range(0, n_slices):\n",
        "                new_nodule.append(nodule[i])\n",
        "        normalized_slices.append(new_nodule)\n",
        "    return normalized_slices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bv9yE5y5HhX",
        "colab_type": "text"
      },
      "source": [
        "## Read images\n",
        "Function to read images from files and returns a list of numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFArGLMh3MDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_images(path, path_features):\n",
        "    '''Reads the images files in our file structure and mounts an array\n",
        "    Parameters:\n",
        "        path (string): path to the nodules folders\n",
        "        path_features (string): path to the features .csv\n",
        "    Returns:\n",
        "        list: list of nodules with slices as Numpy Arrays\n",
        "        features: list of features corresponding to the nodules on list'''\n",
        "\n",
        "    df = pd.read_csv(path_features)\n",
        "    \n",
        "    scaler = MinMaxScaler(copy=False)\n",
        "    df[df.columns[2:74]] = scaler.fit_transform(df[df.columns[2:74]])\n",
        "    \n",
        "    allFeatures = df.values\n",
        "\n",
        "    lista       = []\n",
        "    features    = []\n",
        "\n",
        "    for _, dirs, _ in os.walk(path):\n",
        "        for dirname in sorted(dirs, key=str.lower):\n",
        "            for _, dirs1, _ in os.walk(path + \"/\" + dirname):\n",
        "                for dirname1 in sorted(dirs1, key=str.lower):\n",
        "                    for root2, _, files2 in os.walk(path + \"/\" + dirname + \"/\" + dirname1):\n",
        "                        slices = []\n",
        "                        files2[:] = [re.findall('\\d+', x)[0] for x in files2]\n",
        "\n",
        "                        axis = 0 # To get the Rows indices\n",
        "                        examColumn = 0 # Column of the csv where the exam code is\n",
        "                        noduleColumn = 1 # Column of the csv where the nodule code is\n",
        "\n",
        "                        # index of the rows that have the exam id equal to the exam id of the current nodule\n",
        "                        indExam  = np.where(allFeatures[:,examColumn] == dirname)[axis]\n",
        "\n",
        "                        # index of the rows that have the nodule id equal to the id of the current nodule\n",
        "                        indNodule = np.where(allFeatures[:,noduleColumn] == dirname1)[axis]\n",
        "\n",
        "                        i = np.intersect1d(indExam,indNodule)\n",
        "\n",
        "                        # A list are returned, but there's just one value, so I used its index\n",
        "                        index = 0\n",
        "                        exam = allFeatures[i,examColumn][index]\n",
        "                        nodule = allFeatures[i,noduleColumn][index]\n",
        "\n",
        "                        '''Verify if there's more than one index for each nodule\n",
        "                        and if there's divergence between the nodule location and the\n",
        "                        csv values'''\n",
        "\n",
        "                        if((len(i) > 1) or (str(exam) != str(dirname)) or (str(nodule) != str(dirname1))):\n",
        "                            print(\"Features error!\")\n",
        "                        else:\n",
        "                            '''Transform the list of index with just one value in a\n",
        "                            primitive value to use as index to save the features values'''\n",
        "                            i = i[0]\n",
        "\n",
        "                        for f in sorted(files2, key=float):\n",
        "                            img = imageio.imread(root2 + \"/\" + f + \".png\", as_gray=True)\n",
        "                            slices.append(img)\n",
        "\n",
        "                        lista.append(slices)\n",
        "                        \n",
        "                        if (features_set == 'all'):\n",
        "                          features.append(allFeatures[i,2:73].tolist())\n",
        "                        else:\n",
        "                          features.append(allFeatures[i,feat_input_subset()].tolist())\n",
        "\n",
        "    return lista, features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epU6Ruv140uh",
        "colab_type": "text"
      },
      "source": [
        "## My Kfold\n",
        "k_folder made to get balanced data between benigno and maligno"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUUW5lpf3f28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def my_kfold(ben, mal, f_ben, f_mal, n_splits, ben_rot, mal_rot):\n",
        "    kf = KFold(n_splits)\n",
        "    \n",
        "    f_mal_train, f_mal_test = [], []\n",
        "    mal_train, mal_test = [], []\n",
        "    for train_index, test_index in kf.split(mal):\n",
        "        mal_train.append([mal[index] for index in train_index])\n",
        "        f_mal_train.append([f_mal[index] for index in train_index])\n",
        "\n",
        "        mal_test.append([mal[index] for index in test_index])\n",
        "        f_mal_test.append([f_mal[index] for index in test_index])\n",
        "\n",
        "    ben_train, ben_test = [], []\n",
        "    f_ben_train, f_ben_test = [], []\n",
        "    \n",
        "    # percorro o mal_test para que os folds de test tenham o mesmo número de itens\n",
        "    for (train_index, test_index), mal_te, mal_tr in zip(kf.split(ben), mal_test, mal_train):\n",
        "        \n",
        "        sample = np.random.choice(test_index, len(mal_te), replace=False)\n",
        "        sample_ = np.setdiff1d(test_index, sample)\n",
        "\n",
        "        ben_train_ind = np.concatenate((train_index, sample_))\n",
        "\n",
        "        '''This line guarantees that the ben and mal train batches are the same size'''\n",
        "        ben_train_ind = np.random.choice(ben_train_ind, len(mal_tr), replace=False)\n",
        "\n",
        "        ben_train.append([ben[index] for index in ben_train_ind])\n",
        "        f_ben_train.append([f_ben[index] for index in ben_train_ind])\n",
        "        \n",
        "        ben_test.append([ben[index] for index in sample])\n",
        "        f_ben_test.append([f_ben[index] for index in sample])\n",
        "\n",
        "    X_test, Y_test = [], []\n",
        "    for b, m in zip(ben_test, mal_test):\n",
        "        X_test.append(np.concatenate((b, m), 0))\n",
        "\n",
        "        y_test = len(b) * [0] + len(m) * [1]\n",
        "        Y_test.append(np.array(y_test))\n",
        "\n",
        "    f_test = []\n",
        "    for f_b, f_m in zip(f_ben_test, f_mal_test):\n",
        "        \n",
        "        f_test.append(np.concatenate((f_b, f_m), 0))\n",
        "\n",
        "    X_train, Y_train = [], []\n",
        "    f_train = []\n",
        "    for i in tqdm(range(n_splits)):\n",
        "        print(\"INDEX: \", i)\n",
        "        print(\"ben_train: \", len(ben_train[i]))\n",
        "        print(\"mal_train: \", len(mal_train[i]))\n",
        "        print(\"ben_test: \",  len(ben_test[i]))\n",
        "        print(\"mal_test: \",  len(mal_test[i]))\n",
        "        \n",
        "        b, m = ben_train[i], mal_train[i]\n",
        "        f_b_train, f_m_train = f_ben_train[i], f_mal_train[i]\n",
        "\n",
        "        X_train.append(np.concatenate((b, m), 0))\n",
        "        f_train.append(np.concatenate((f_b_train, f_m_train), 0))\n",
        "\n",
        "        y_train = len(b) * [0] + len(m) * [1]\n",
        "        Y_train.append(np.array(y_train))\n",
        "\n",
        "    return X_train, X_test, f_train, f_test, Y_train, Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBFxM-wS4nVo",
        "colab_type": "text"
      },
      "source": [
        "## Get folds\n",
        "Function that is called to get the folds of the cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyB7azPc3srM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_folds(basedir, n_slices, strategy='first', repeat=False, features=None):\n",
        "    ben_dir = basedir + \"benigno\"\n",
        "    mal_dir = basedir + \"maligno\"\n",
        "\n",
        "    ben, f_ben = read_images(ben_dir, features)\n",
        "    mal, f_mal = read_images(mal_dir, features)\n",
        "\n",
        "    if strategy == 'first':\n",
        "        ben = normalize_first(ben, n_slices, repeat)\n",
        "        mal = normalize_first(mal, n_slices, repeat)\n",
        "\n",
        "    ben = np.concatenate(ben).reshape(len(ben), n_slices, images_resolution, images_resolution, 1)\n",
        "    mal = np.concatenate(mal).reshape(len(mal), n_slices, images_resolution, images_resolution, 1)\n",
        "\n",
        "    ben = np.moveaxis(ben, 1, 3)\n",
        "    mal = np.moveaxis(mal, 1, 3)\n",
        "\n",
        "    ben_zip = list(zip(ben, f_ben))\n",
        "    np.random.shuffle(ben_zip)\n",
        "    ben, f_ben = zip(*ben_zip)\n",
        "\n",
        "    mal_zip = list(zip(mal, f_mal))\n",
        "    np.random.shuffle(mal_zip)\n",
        "    mal, f_mal = zip(*mal_zip)\n",
        "\n",
        "    X_train, X_test, f_train, f_test, Y_train, Y_test = my_kfold(ben, mal, f_ben, \n",
        "                                                                 f_mal, number_of_folds, \n",
        "                                                                 rotations_of_benignant, \n",
        "                                                                 rotations_of_malignant)\n",
        "\n",
        "    return X_train, X_test, f_train, f_test, Y_train, Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDubOPP3YKV4",
        "colab_type": "text"
      },
      "source": [
        "# Valition code\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FLvGJNFYKV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model(conv1, dense1, dense2, drop1, drop2):\n",
        "    input_layer = Input(input_shape)\n",
        "    \n",
        "    if (feature_injection):\n",
        "      print(\"(features input creation) Feature injection ACTIVATED - \" + features_set)\n",
        "      input_features_layer = Input(feature_input_shape)\n",
        "    else:\n",
        "      print(\"Feature injection DEACTIVATED\")\n",
        "      \n",
        "    conv_layer1    = Conv3D(filters=conv1, kernel_size=(3, 3, 3), \n",
        "                        activation='relu')(input_layer)\n",
        "    pooling_layer1 = MaxPool3D(pool_size=(2, 2, 2))(conv_layer1)\n",
        "    \n",
        "    flatten_layer  = Flatten()(pooling_layer1)\n",
        "    \n",
        "    if (feature_injection and layer_to_be_injected == 'flatten'):\n",
        "      print(\"Injecting - \" + features_set + \" - on Flatten!\")\n",
        "      flatten_layer = concatenate([flatten_layer, input_features_layer])\n",
        "\n",
        "    dense_layer1 = Dense(units=dense1, activation='relu')(flatten_layer)\n",
        "    \n",
        "    if (feature_injection and layer_to_be_injected == 'dense1'):\n",
        "      print(\"Injecting - \" + features_set + \" - on Dense1!\")\n",
        "      dense_layer1 = concatenate([dense_layer1, input_features_layer])\n",
        "    \n",
        "    dense_layer1 = Dropout(drop1)(dense_layer1)\n",
        "\n",
        "    dense_layer2 = Dense(units=dense2, activation='relu')(dense_layer1)\n",
        "    \n",
        "    if (feature_injection and layer_to_be_injected == 'dense2'):\n",
        "      print(\"Injecting - \" + features_set + \" - on Dense2!\")\n",
        "      dense_layer2 = concatenate([dense_layer2, input_features_layer])\n",
        "    \n",
        "    dense_layer2 = Dropout(drop2)(dense_layer2)\n",
        "\n",
        "    output_layer = Dense(units=1, activation='sigmoid')(dense_layer2)\n",
        "    \n",
        "    model = []\n",
        "    if (feature_injection):\n",
        "      print(\"(model creation) Feature - \" + features_set + \" - injection ACTIVATED\")\n",
        "      model = Model(inputs=[input_layer, input_features_layer], outputs=output_layer)\n",
        "    else:\n",
        "      print(\"(model creation) Feature injection DEACTIVATED\")\n",
        "      model = Model(inputs=input_layer, outputs=output_layer)\n",
        "      \n",
        "    opt = optimizers.RMSprop(lr=0.0001)\n",
        "\n",
        "    model.compile(loss=binary_crossentropy, optimizer=opt, \n",
        "    metrics=['accuracy', km.binary_true_positive(), km.binary_true_negative(), \n",
        "                km.binary_false_positive(), km.binary_false_negative(), \n",
        "                km.binary_f1_score()])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxfPLx_XYKWG",
        "colab_type": "text"
      },
      "source": [
        "## Cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5q4RtMfYKWO",
        "colab_type": "code",
        "outputId": "e9a2217c-4e3c-486a-edfd-4eb41660bd85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "start = time.time()\n",
        "for i in range(number_of_validations):\n",
        "    X_train_, X_test_, f_train_, f_test_, Y_train_, Y_test_=  get_folds(basedir=images_dir, \n",
        "                                                                        n_slices=slices_per_nodule, \n",
        "                                                                        strategy=strategy, \n",
        "                                                                        repeat=repeat_slices,\n",
        "                                                                        features=features_path)\n",
        "    i = 0\n",
        "    best_run = {}\n",
        "    for i in range(30):\n",
        "      print(\"Run :\" + str(i))\n",
        "      conv1  = np.random.choice(conv1_search_space, size=1)[0]\n",
        "      dense1 = np.random.choice(dense1_search_space, size=1)[0]\n",
        "      dense2 = np.random.choice(dense2_search_space, size=1)[0]\n",
        "      \n",
        "      drop1 = -1\n",
        "      while (drop1 < 0 or drop1 > 0.5):\n",
        "        drop1 = drop_random_values_gen.rvs()\n",
        "        \n",
        "      drop2 = -1\n",
        "      while (drop2 < 0 or drop2 > 0.5):\n",
        "        drop2 = drop_random_values_gen.rvs()\n",
        "      \n",
        "      m = {'acc': [], 'auc': []}\n",
        "\n",
        "      model = get_model(conv1, dense1, dense2, drop1, drop2)\n",
        "\n",
        "      for X_train, X_test, f_train, f_test, Y_train, Y_test in zip(X_train_, X_test_, f_train_, f_test_, Y_train_, Y_test_):\n",
        "        if (feature_injection):\n",
        "          print(\"(fitting) Feature - \" + features_set + \" - injection ACTIVATED\")\n",
        "          model.fit([X_train, f_train], Y_train, batch_size=128, epochs=10, verbose=0)\n",
        "        else:\n",
        "          print(\"(fitting) Feature injection DEACTIVATED\")\n",
        "          model.fit(X_train, Y_train, batch_size=128, epochs=10, verbose=0)\n",
        "          \n",
        "        scores = []\n",
        "        if (feature_injection):\n",
        "          print(\"(evaluating) Feature - \" + features_set + \" - injection ACTIVATED\")\n",
        "          scores = model.evaluate([X_test, f_test], Y_test, verbose=0)\n",
        "        else:\n",
        "          print(\"(evaluating) Feature injection DEACTIVATED\")\n",
        "          scores = model.evaluate(X_test, Y_test, verbose=0)\n",
        "          \n",
        "        tp, tn, fp, fn = scores[2], scores[3], scores[4], scores[5]\n",
        "        \n",
        "        acc = scores[1]*100\n",
        "        \n",
        "        # AUC\n",
        "        pred = []\n",
        "        \n",
        "        if (feature_injection):\n",
        "          print(\"(predicting) Feature - \" + features_set + \" - injection ACTIVATED\")\n",
        "          pred = model.predict([X_test, f_test]).ravel()\n",
        "        else:\n",
        "          print(\"(predicting) Feature injection DEACTIVATED\")\n",
        "          pred = model.predict(X_test).ravel()\n",
        "        \n",
        "        fpr, tpr, thresholds_keras = roc_curve(Y_test, pred)\n",
        "        auc_val = auc(fpr, tpr)\n",
        "        \n",
        "        print('Test accuracy: ', acc)\n",
        "        print('Test AUC: ', auc_val)\n",
        "\n",
        "        m['acc'].append(acc)\n",
        "        m['auc'].append(auc_val)\n",
        "      \n",
        "      run_output = {'acc': np.mean(m['acc']), 'auc': np.mean(m['auc']), 'conv1': conv1, 'dense1': dense1, 'dense2': dense2, 'drop1': drop1, 'drop2': drop2}\n",
        "      print(run_output)\n",
        "      \n",
        "      if (len(best_run) == 0 or run_output['auc'] > best_run['auc']):\n",
        "        best_run = run_output\n",
        "      elif (run_output['auc'] == best_run['auc'] and run_output['acc'] > best_run['acc']):\n",
        "        best_run = run_output\n",
        "\n",
        "end = time.time()\n",
        "\n",
        "print(\"Time on optimization:\", (end - start)/60, \"minutes\")\n",
        "\n",
        "print()\n",
        "print('Summary of the best model: -----------------------')\n",
        "print(best_run)\n",
        "c1 = best_run['conv1']\n",
        "d1 = best_run['dense1']\n",
        "d2 = best_run['dense2']\n",
        "dr1 = best_run['drop1']\n",
        "dr2 = best_run['drop2']\n",
        "\n",
        "print('Conv 1:', c1, 'unidades')\n",
        "print('Dense 1:', d1, 'unidades')\n",
        "print('Dense 2:', d2, 'unidades')\n",
        "print('Dropout 1:', dr1)\n",
        "print('Dropout 2:', dr2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 2/10 [00:00<00:00, 14.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INDEX:  0\n",
            "ben_train:  240\n",
            "mal_train:  240\n",
            "ben_test:  27\n",
            "mal_test:  27\n",
            "INDEX:  1\n",
            "ben_train:  240\n",
            "mal_train:  240\n",
            "ben_test:  27\n",
            "mal_test:  27\n",
            "INDEX:  2\n",
            "ben_train:  240\n",
            "mal_train:  240\n",
            "ben_test:  27\n",
            "mal_test:  27\n",
            "INDEX:  "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 4/10 [00:00<00:00, 14.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "ben_train:  240\n",
            "mal_train:  240\n",
            "ben_test:  27\n",
            "mal_test:  27\n",
            "INDEX:  4\n",
            "ben_train:  240\n",
            "mal_train:  240\n",
            "ben_test:  27\n",
            "mal_test:  27\n",
            "INDEX:  5\n",
            "ben_train:  240\n",
            "mal_train:  240\n",
            "ben_test:  27\n",
            "mal_test:  27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|████████  | 8/10 [00:00<00:00, 14.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INDEX:  6\n",
            "ben_train:  240\n",
            "mal_train:  240\n",
            "ben_test:  27\n",
            "mal_test:  27\n",
            "INDEX:  7\n",
            "ben_train:  241\n",
            "mal_train:  241\n",
            "ben_test:  26\n",
            "mal_test:  26\n",
            "INDEX:  8\n",
            "ben_train:  241\n",
            "mal_train:  241\n",
            "ben_test:  26\n",
            "mal_test:  26\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 10/10 [00:00<00:00, 14.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INDEX:  9\n",
            "ben_train:  241\n",
            "mal_train:  241\n",
            "ben_test:  26\n",
            "mal_test:  26\n",
            "Run :0\n",
            "(features input creation) Feature injection ACTIVATED - all\n",
            "Injecting - all - on Flatten!\n",
            "(model creation) Feature - all - injection ACTIVATED\n",
            "(fitting) Feature - all - injection ACTIVATED\n",
            "(evaluating) Feature - all - injection ACTIVATED\n",
            "(predicting) Feature - all - injection ACTIVATED\n",
            "Test accuracy:  85.1851862889749\n",
            "Test AUC:  0.9012345679012346\n",
            "(fitting) Feature - all - injection ACTIVATED\n",
            "(evaluating) Feature - all - injection ACTIVATED\n",
            "(predicting) Feature - all - injection ACTIVATED\n",
            "Test accuracy:  77.77777821929367\n",
            "Test AUC:  0.8895747599451302\n",
            "(fitting) Feature - all - injection ACTIVATED\n",
            "(evaluating) Feature - all - injection ACTIVATED\n",
            "(predicting) Feature - all - injection ACTIVATED\n",
            "Test accuracy:  87.03703681627908\n",
            "Test AUC:  0.9293552812071331\n",
            "(fitting) Feature - all - injection ACTIVATED\n",
            "(evaluating) Feature - all - injection ACTIVATED\n",
            "(predicting) Feature - all - injection ACTIVATED\n",
            "Test accuracy:  79.62962940887168\n",
            "Test AUC:  0.887517146776406\n",
            "(fitting) Feature - all - injection ACTIVATED\n",
            "(evaluating) Feature - all - injection ACTIVATED\n",
            "(predicting) Feature - all - injection ACTIVATED\n",
            "Test accuracy:  87.03703814082675\n",
            "Test AUC:  0.9355281207133058\n",
            "(fitting) Feature - all - injection ACTIVATED\n",
            "(evaluating) Feature - all - injection ACTIVATED\n",
            "(predicting) Feature - all - injection ACTIVATED\n",
            "Test accuracy:  72.22222133919045\n",
            "Test AUC:  0.8333333333333333\n",
            "(fitting) Feature - all - injection ACTIVATED\n",
            "(evaluating) Feature - all - injection ACTIVATED\n",
            "(predicting) Feature - all - injection ACTIVATED\n",
            "Test accuracy:  85.1851862889749\n",
            "Test AUC:  0.9465020576131687\n",
            "(fitting) Feature - all - injection ACTIVATED\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}