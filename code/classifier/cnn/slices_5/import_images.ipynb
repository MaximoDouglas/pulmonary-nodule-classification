{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "import_images.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "sdyfwb_aZWNB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Configure enviroment"
      ]
    },
    {
      "metadata": {
        "id": "q88TRW8TZIqs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8jpumH0kZcy_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ]
    },
    {
      "metadata": {
        "id": "8b4a2UbMY_2u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import itertools\n",
        "import re\n",
        "import os\n",
        "import imageio\n",
        "import numpy as np\n",
        "from scipy.ndimage import rotate\n",
        "from sklearn.model_selection import KFold\n",
        "from tqdm import tqdm\n",
        "import shutil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fIGx04rqrZEh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Settings"
      ]
    },
    {
      "metadata": {
        "id": "ZfNtVy7rrYMI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Random seed, to help on reproduction of this study\n",
        "np.random.seed(1937)\n",
        "\n",
        "# Resolution of the images\n",
        "RES = 64\n",
        "\n",
        "# Size of test split\n",
        "TEST_SIZE = 50\n",
        "\n",
        "\n",
        "# ------------------------------data type settings------------------------------\n",
        "\n",
        "# Number of slices for each nodule\n",
        "SLICES = 5\n",
        "\n",
        "# Strategy used to slices selection\n",
        "STRATEGY = 'balanced'\n",
        "\n",
        "# Determinates if the repeating of slices is allowed\n",
        "REPEAT = False\n",
        "\n",
        "prefix = \"/content/drive/My Drive/Pesquisa - Dicom images/data\"\n",
        "\n",
        "# Folder where the numpy files will be saved\n",
        "np_folder = prefix + \"/nps/solid-nodules/data-\" + str(SLICES) + \"-\" + str(STRATEGY)\n",
        "if (REPEAT):\n",
        "    np_folder += \"-repeat\"\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "base_dir = prefix + \"/images/solid-nodules-with-attributes/\"\n",
        "\n",
        "# Folder for the benigno image files\n",
        "ben_dir = base_dir + \"benigno\"\n",
        "\n",
        "# Folder for the maligno image files\n",
        "mal_dir = base_dir + \"maligno\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TYDtO6zqroRI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Balanced Strategy"
      ]
    },
    {
      "metadata": {
        "id": "JkT3yeePrrye",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalize_balanced(nodules, n_slices, repeat=False):\n",
        "    '''Normalizes the nodule slices number:\n",
        "    - A nodule with less than n slices is completed with black slices\n",
        "    - A nodule with more than n slices have its first and last one selected, plus\n",
        "    the 1 + (n-1/5)*k, where k = {1, 2, 3, 4}\n",
        "    '''\n",
        "    normalized_slices = []\n",
        "\n",
        "    for nodule in nodules:\n",
        "        new_nodule = []\n",
        "        # adds black slices\n",
        "\n",
        "        if repeat:\n",
        "            times = math.ceil(n_slices/len(nodule))\n",
        "            nodule = list(itertools.chain.from_iterable(itertools.repeat(x, times) for x in nodule))\n",
        "\n",
        "        if len(nodule) <= n_slices:\n",
        "                for slice in nodule:\n",
        "                    new_nodule.append(slice)\n",
        "                for i in range(n_slices - len(nodule)):\n",
        "                    new_nodule.append(np.zeros((RES, RES)))\n",
        "        elif len(nodule) > n_slices:\n",
        "            new_nodule.append(nodule[0])\n",
        "            for k in range(1, n_slices-1):\n",
        "                new_nodule.append(nodule[round(1 + ((len(nodule) - 1) / (n_slices-1)) * k)])\n",
        "            new_nodule.append(nodule[-1])\n",
        "        normalized_slices.append(new_nodule)\n",
        "    return normalized_slices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9IjafQlhrxCv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Get first slices Strategy"
      ]
    },
    {
      "metadata": {
        "id": "-5V5vO3Jr29N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalize_first(nodules, n_slices, repeat=False):\n",
        "    '''Normalizes the nodule slices number:\n",
        "    - A nodule with less than n slices is completed with black slices\n",
        "    - A nodule with more than n slices have its n first slices selected\n",
        "    '''\n",
        "    normalized_slices = []\n",
        "\n",
        "    for nodule in nodules:\n",
        "        new_nodule = []\n",
        "\n",
        "        if repeat:\n",
        "            times = math.ceil(n_slices/len(nodule))\n",
        "            nodule = list(itertools.chain.from_iterable(itertools.repeat(x, times) for x in nodule))\n",
        "\n",
        "        if len(nodule) <= n_slices:\n",
        "                for slice in nodule:\n",
        "                    new_nodule.append(slice)\n",
        "                for i in range(n_slices - len(nodule)):\n",
        "                    new_nodule.append(np.zeros((RES, RES)))\n",
        "        elif len(nodule) > n_slices:\n",
        "            for i in range(0, n_slices):\n",
        "                new_nodule.append(nodule[i])\n",
        "        normalized_slices.append(new_nodule)\n",
        "    return normalized_slices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5i4fM2JXr7w3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Read images and features, connecting each nodule to its features"
      ]
    },
    {
      "metadata": {
        "id": "cXm9uJI2r9V0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_images(path, category):\n",
        "    '''Reads the images files in our file structure and mounts an array\n",
        "    Parameters:\n",
        "        path (string): path to the nodules folders\n",
        "        category (string): benigno or maligno\n",
        "    Returns:\n",
        "        list: list of nodules with slices as Numpy Arrays\n",
        "    '''\n",
        "    lista = []\n",
        "\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for dirname in sorted(dirs, key=str.lower):\n",
        "            for root1, dirs1, files1 in os.walk(path + \"/\" + dirname):\n",
        "                for dirname1 in sorted(dirs1, key=str.lower):\n",
        "                    for root2, dirs2, files2 in os.walk(path + \"/\" + dirname + \"/\" + dirname1):\n",
        "                        slices = []\n",
        "                        files2[:] = [re.findall('\\d+', x)[0] for x in files2]\n",
        "\n",
        "                        for f in sorted(files2, key=float):\n",
        "                            img = imageio.imread(root2 + \"/\" + f + \".png\", as_gray=True)\n",
        "                            slices.append(img)\n",
        "\n",
        "                        lista.append(slices)\n",
        "    return lista"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pq4E05S2sapI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data augmentation"
      ]
    },
    {
      "metadata": {
        "id": "zWaTcrmSsbZ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rotate_slices(slices, times, mode='constant'):\n",
        "    ''' Rotates a list of images n times'''\n",
        "    rotated = slices\n",
        "    angle = 360/times\n",
        "    for i in range(1, times):\n",
        "        temp = rotate(slices, i*angle, (1, 2), reshape=False, mode = mode)\n",
        "        rotated = np.concatenate([rotated, temp])\n",
        "    return rotated"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BmrOsaAOtu3W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Script to read and save data on numpy files"
      ]
    },
    {
      "metadata": {
        "id": "zhnOboUGtvtO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d3cc429-ca38-47da-e4c2-694ee64f225b"
      },
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    print(\"Lendo imagens do disco\")\n",
        "\n",
        "    ben = read_images(ben_dir, \"benigno\")\n",
        "    mal = read_images(mal_dir, \"maligno\")\n",
        "\n",
        "    if (STRATEGY == 'first'):\n",
        "        ben = normalize_first(ben, SLICES, REPEAT)\n",
        "        mal = normalize_first(mal, SLICES, REPEAT)\n",
        "    else:\n",
        "        ben = normalize_balanced(ben, SLICES, REPEAT)\n",
        "        mal = normalize_balanced(mal, SLICES, REPEAT)\n",
        "\n",
        "    print(\"Mudando a forma\")\n",
        "\n",
        "    print(\">\", len(ben))\n",
        "\n",
        "    ben = np.concatenate(ben).reshape(len(ben), SLICES, RES, RES, 1)\n",
        "    mal = np.concatenate(mal).reshape(len(mal), SLICES, RES, RES, 1)\n",
        "\n",
        "    print(\"Trocando os eixos\")\n",
        "\n",
        "    print(\"Antes: \", ben.shape)\n",
        "\n",
        "    ben = np.moveaxis(ben, 1, 3)\n",
        "    mal = np.moveaxis(mal, 1, 3)\n",
        "\n",
        "    print(\"Depois: \", ben.shape)\n",
        "\n",
        "    print(\"Separando dados de teste\")\n",
        "\n",
        "    ben_test_indices = np.random.choice(len(ben), TEST_SIZE, replace=False)\n",
        "    mal_test_indices = np.random.choice(len(mal), TEST_SIZE, replace=False)\n",
        "\n",
        "    ben_test = [ben[i] for i in ben_test_indices]\n",
        "    mal_test = [mal[i] for i in mal_test_indices]\n",
        "\n",
        "    ben_test = np.array(ben_test)\n",
        "    mal_test = np.array(mal_test)\n",
        "\n",
        "    ben_train = np.delete(ben, ben_test_indices, axis = 0)\n",
        "    mal_train = np.delete(mal, mal_test_indices, axis = 0)\n",
        "\n",
        "    del(ben, mal, ben_dir, mal_dir, ben_test_indices, mal_test_indices)\n",
        "\n",
        "    print(\"Aumento de base\")\n",
        "\n",
        "    ben_train = rotate_slices(ben_train, 5)#, 'reflect')\n",
        "    mal_train = rotate_slices(mal_train, 13)#, 'reflect')\n",
        "\n",
        "    print(\"Juntando benignos e malignos\")\n",
        "\n",
        "    X_train = np.concatenate([ben_train, mal_train])\n",
        "    X_test = np.concatenate([ben_test, mal_test])\n",
        "\n",
        "    print(\"Gerando labels\")\n",
        "\n",
        "    train_labels = len(ben_train) * [0] + len(mal_train) * [1]\n",
        "    test_labels = len(ben_test) * [0] + len(mal_test) * [1]\n",
        "\n",
        "    print(\"Tipo categórico\")\n",
        "\n",
        "    Y_train = np.array(train_labels)\n",
        "    Y_test = np.array(test_labels)\n",
        "\n",
        "    data = np_folder\n",
        "\n",
        "    shutil.rmtree(data, ignore_errors=True)\n",
        "    os.mkdir(data)\n",
        "\n",
        "    np.save(data + \"/X_train.npy\", X_train)\n",
        "    np.save(data + \"/X_test.npy\", X_test)\n",
        "    np.save(data + \"/Y_train.npy\", Y_train)\n",
        "    np.save(data + \"/Y_test.npy\", Y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lendo imagens do disco\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}