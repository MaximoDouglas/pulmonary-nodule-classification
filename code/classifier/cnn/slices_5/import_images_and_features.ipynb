{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "import_images_and_features.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "sdyfwb_aZWNB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Configure enviroment"
      ]
    },
    {
      "metadata": {
        "id": "q88TRW8TZIqs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8jpumH0kZcy_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Images and features processor\n",
        "The following block reads images and features and saves it as numpy files, separating train and test folds."
      ]
    },
    {
      "metadata": {
        "id": "8b4a2UbMY_2u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "import itertools\n",
        "import re\n",
        "import os\n",
        "import imageio\n",
        "import numpy as np\n",
        "from scipy.ndimage import rotate\n",
        "from sklearn.model_selection import KFold\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "import pandas as pd\n",
        "\n",
        "np.random.seed(1937)\n",
        "\n",
        "RES = 64\n",
        "TEST_SIZE = 50\n",
        "\n",
        "SLICES = 5\n",
        "STRATEGY = 'first'\n",
        "REPEAT = False\n",
        "\n",
        "data_fold = \"/content/drive/My Drive/tcc/data/np_with_features/data-\" + str(SLICES) + \"-\" + str(STRATEGY)\n",
        "if (REPEAT):\n",
        "    data_fold += \"-repeat\"\n",
        "\n",
        "def normalize_balanced(nodules, n_slices, repeat=False):\n",
        "    '''Normalizes the nodule slices number:\n",
        "    - A nodule with less than n slices is completed with black slices\n",
        "    - A nodule with more than n slices have its first and last one selected, plus\n",
        "    the 1 + (n-1/5)*k, where k = {1, 2, 3, 4}\n",
        "    '''\n",
        "    normalized_slices = []\n",
        "\n",
        "    for nodule in nodules:\n",
        "        new_nodule = []\n",
        "        # adds black slices\n",
        "\n",
        "        if repeat:\n",
        "            times = math.ceil(n_slices/len(nodule))\n",
        "            nodule = list(itertools.chain.from_iterable(itertools.repeat(x, times) for x in nodule))\n",
        "\n",
        "        if len(nodule) <= n_slices:\n",
        "                for slice in nodule:\n",
        "                    new_nodule.append(slice)\n",
        "                for i in range(n_slices - len(nodule)):\n",
        "                    new_nodule.append(np.zeros((RES, RES)))\n",
        "        elif len(nodule) > n_slices:\n",
        "            new_nodule.append(nodule[0])\n",
        "            for k in range(1, n_slices-1):\n",
        "                new_nodule.append(nodule[round(1 + ((len(nodule) - 1) / (n_slices-1)) * k)])\n",
        "            new_nodule.append(nodule[-1])\n",
        "        normalized_slices.append(new_nodule)\n",
        "    return normalized_slices\n",
        "\n",
        "def normalize_first(nodules, n_slices, repeat=False):\n",
        "    '''Normalizes the nodule slices number:\n",
        "    - A nodule with less than n slices is completed with black slices\n",
        "    - A nodule with more than n slices have its n first slices selected\n",
        "    '''\n",
        "    normalized_slices = []\n",
        "\n",
        "    for nodule in nodules:\n",
        "        new_nodule = []\n",
        "\n",
        "        if repeat:\n",
        "            times = math.ceil(n_slices/len(nodule))\n",
        "            nodule = list(itertools.chain.from_iterable(itertools.repeat(x, times) for x in nodule))\n",
        "\n",
        "        if len(nodule) <= n_slices:\n",
        "                for slice in nodule:\n",
        "                    new_nodule.append(slice)\n",
        "                for i in range(n_slices - len(nodule)):\n",
        "                    new_nodule.append(np.zeros((RES, RES)))\n",
        "        elif len(nodule) > n_slices:\n",
        "            for i in range(0, n_slices):\n",
        "                new_nodule.append(nodule[i])\n",
        "        normalized_slices.append(new_nodule)\n",
        "    return normalized_slices\n",
        "\n",
        "def read_images(path, path_features):\n",
        "    '''Reads the images files in our file structure and mounts an array\n",
        "    Parameters:\n",
        "        path (string): path to the nodules folders\n",
        "        path_features (string): path to the features .csv\n",
        "    Returns:\n",
        "        list: list of nodules with slices as Numpy Arrays\n",
        "        features: list of features corresponding to the nodules on list\n",
        "    '''\n",
        "\n",
        "    df = pd.read_csv(path_features)\n",
        "    allFeatures = df.values\n",
        "\n",
        "    lista       = []\n",
        "    features    = []\n",
        "\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for dirname in sorted(dirs, key=str.lower):\n",
        "            for root1, dirs1, files1 in os.walk(path + \"/\" + dirname):\n",
        "                for dirname1 in sorted(dirs1, key=str.lower):\n",
        "                    for root2, dirs2, files2 in os.walk(path + \"/\" + dirname + \"/\" + dirname1):\n",
        "                        slices = []\n",
        "                        files2[:] = [re.findall('\\d+', x)[0] for x in files2]\n",
        "\n",
        "                        axis = 0 # To get the Rows indices\n",
        "                        examColumn = 0 # Column of the csv where the exam code is\n",
        "                        noduleColumn = 1 # Column of the csv where the nodule code is\n",
        "\n",
        "                        # index of the rows that have the exam id equal to the exam id of the current nodule\n",
        "                        indExam  = np.where(allFeatures[:,examColumn] == dirname)[axis]\n",
        "\n",
        "                        # index of the rows that have the nodule id equal to the id of the current nodule\n",
        "                        indNodule = np.where(allFeatures[:,noduleColumn] == dirname1)[axis]\n",
        "\n",
        "                        i = np.intersect1d(indExam,indNodule)\n",
        "\n",
        "                        # A list are returned, but there's just one value, so I used its index\n",
        "                        index = 0\n",
        "                        exam = allFeatures[i,examColumn][index]\n",
        "                        nodule = allFeatures[i,noduleColumn][index]\n",
        "\n",
        "                        '''Verify if there's more than one index for each nodule\n",
        "                        and if there's divergence between the nodule location and the\n",
        "                        csv values'''\n",
        "\n",
        "                        if((len(i) > 1) or (str(exam) != str(dirname)) or (str(nodule) != str(dirname1))):\n",
        "                            print(\"Features error!\")\n",
        "                        else:\n",
        "                            '''Transform the list of index with just one value in a\n",
        "                            primitive value to use as index to save the features values'''\n",
        "                            i = i[0]\n",
        "\n",
        "                        for f in sorted(files2, key=float):\n",
        "                            img = imageio.imread(root2 + \"/\" + f + \".png\", as_gray=True)\n",
        "                            slices.append(img)\n",
        "\n",
        "                        lista.append(slices)\n",
        "                        features.append(allFeatures[i,2:75].tolist())\n",
        "\n",
        "    return lista, features\n",
        "\n",
        "def rotate_slices(nodules, f, times, mode='constant'):\n",
        "    ''' Rotates a list of images n times'''\n",
        "    rotated = nodules\n",
        "    angle = 360/times\n",
        "    rep_feat = f\n",
        "\n",
        "    for i in range(1, times):\n",
        "        temp = rotate(nodules, i*angle, (1, 2), reshape=False, mode = mode)\n",
        "        rotated     = np.concatenate([rotated, temp])\n",
        "        rep_feat    = np.concatenate([rep_feat, f])\n",
        "\n",
        "    return rotated, rep_feat\n",
        "\n",
        "def rotate_slices_slow(nodules, f, times, mode='constant'):\n",
        "    ''' Rotates a list of images n times'''\n",
        "    rotated = nodules\n",
        "    rep_feat = f\n",
        "    angle = 360/times\n",
        "\n",
        "    for ind, nd in enumerate(nodules):\n",
        "        temp_nodule = []\n",
        "        temp_f = []\n",
        "\n",
        "        temp_nodule.append(nd)\n",
        "        temp_f.append(f[ind])\n",
        "\n",
        "        for i in range(1, times):\n",
        "            temp_new = rotate(nd, i*angle, (0, 1), reshape=False, mode = mode)\n",
        "            temp_nodule.append(temp_new)\n",
        "            temp_f.append(f[ind])\n",
        "\n",
        "        rotated = np.append(rotated, temp_nodule, axis=0)\n",
        "        rep_feat = np.append(rep_feat, temp_f, axis=0)\n",
        "\n",
        "    return rotated, rep_feat\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ben_dir = \"/content/drive/My Drive/tcc/data/images/solid-nodules-with-attributes/benigno\"\n",
        "    mal_dir = \"/content/drive/My Drive/tcc/data/images/solid-nodules-with-attributes/maligno\"\n",
        "    features_path = \"/content/drive/My Drive/tcc/data/features/solidNodules.csv\"\n",
        "\n",
        "    print(\"Lendo imagens do disco\")\n",
        "\n",
        "    ben, f_ben = read_images(ben_dir, features_path)\n",
        "    mal, f_mal = read_images(mal_dir, features_path)\n",
        "\n",
        "    if (STRATEGY == 'first'):\n",
        "        ben = normalize_first(ben, SLICES, REPEAT)\n",
        "        mal = normalize_first(mal, SLICES, REPEAT)\n",
        "    else:\n",
        "        ben = normalize_balanced(ben, SLICES, REPEAT)\n",
        "        mal = normalize_balanced(mal, SLICES, REPEAT)\n",
        "\n",
        "    print(\"Mudando a forma\")\n",
        "\n",
        "    print(\">\", len(ben))\n",
        "\n",
        "    ben = np.concatenate(ben).reshape(len(ben), SLICES, RES, RES, 1)\n",
        "    mal = np.concatenate(mal).reshape(len(mal), SLICES, RES, RES, 1)\n",
        "\n",
        "    print(\"Trocando os eixos\")\n",
        "\n",
        "    print(\"Antes: \", ben.shape)\n",
        "\n",
        "    ben = np.moveaxis(ben, 1, 3)\n",
        "    mal = np.moveaxis(mal, 1, 3)\n",
        "\n",
        "    print(\"Depois: \", ben.shape)\n",
        "\n",
        "    print(\"Separando dados de teste\")\n",
        "\n",
        "    ben_test_indices = np.random.choice(len(ben), TEST_SIZE, replace=False)\n",
        "    mal_test_indices = np.random.choice(len(mal), TEST_SIZE, replace=False)\n",
        "\n",
        "    ben_test = [ben[i] for i in ben_test_indices]\n",
        "    f_ben_test = [f_ben[i] for i in ben_test_indices]\n",
        "\n",
        "    mal_test = [mal[i] for i in mal_test_indices]\n",
        "    f_mal_test = [f_mal[i] for i in mal_test_indices]\n",
        "\n",
        "    ben_test = np.array(ben_test)\n",
        "    f_ben_test = np.array(f_ben_test)\n",
        "\n",
        "    mal_test = np.array(mal_test)\n",
        "    f_mal_test = np.array(f_mal_test)\n",
        "\n",
        "    ben_train = np.delete(ben, ben_test_indices, axis = 0)\n",
        "    f_ben_train = np.delete(f_ben, ben_test_indices, axis = 0)\n",
        "\n",
        "    mal_train = np.delete(mal, mal_test_indices, axis = 0)\n",
        "    f_mal_train = np.delete(f_mal, mal_test_indices, axis = 0)\n",
        "\n",
        "    del(ben, f_ben, mal, f_mal, ben_dir, mal_dir, features_path, ben_test_indices, mal_test_indices)\n",
        "\n",
        "    print(\"Aumento de base\")\n",
        "\n",
        "    ben_train, f_ben_train = rotate_slices(nodules=ben_train, f=f_ben_train, times=5)\n",
        "    mal_train, f_mal_train = rotate_slices(nodules=mal_train, f=f_mal_train, times=13)\n",
        "\n",
        "    print(\"Juntando benignos e malignos\")\n",
        "\n",
        "    X_train = np.concatenate([ben_train, mal_train])\n",
        "    f_train = np.concatenate([f_ben_train, f_mal_train])\n",
        "\n",
        "    X_test  = np.concatenate([ben_test, mal_test])\n",
        "    f_test  = np.concatenate([f_ben_test, f_mal_test])\n",
        "\n",
        "    print('Shapes: ')\n",
        "    print('X_train: ' + str(X_train.shape))\n",
        "    print('f_train: ' + str(f_train.shape))\n",
        "\n",
        "    print()\n",
        "    print('X_test: ' + str(X_test.shape))\n",
        "    print('f_test: ' + str(f_test.shape))\n",
        "\n",
        "    print(\"Gerando labels\")\n",
        "\n",
        "    train_labels = len(ben_train) * [0] + len(mal_train) * [1]\n",
        "    test_labels = len(ben_test) * [0] + len(mal_test) * [1]\n",
        "\n",
        "    print(\"Tipo categórico\")\n",
        "\n",
        "    Y_train = np.array(train_labels)\n",
        "    Y_test = np.array(test_labels)\n",
        "\n",
        "    data = data_fold\n",
        "\n",
        "    shutil.rmtree(data, ignore_errors=True)\n",
        "    os.mkdir(data)\n",
        "\n",
        "    np.save(data + \"/f_test.npy\", f_test)\n",
        "    np.save(data + \"/X_train.npy\", X_train)\n",
        "    np.save(data + \"/X_test.npy\", X_test)\n",
        "    np.save(data + \"/Y_train.npy\", Y_train)\n",
        "    np.save(data + \"/Y_test.npy\", Y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}